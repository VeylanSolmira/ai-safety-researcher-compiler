# Data Poisoning

## Overview


## Human Data Poisoning (Current):

Humans inject malicious data into training sets
Static corruption - poison data doesn't adapt
Requires human understanding of target model vulnerabilities
Limited by human knowledge of ML systems

## AI-Driven Data Poisoning (Emerging):

AI systems could generate sophisticated poisoned data for future AI training
Dynamic corruption - poison data could be designed to activate under specific conditions
AI systems have deep understanding of neural network vulnerabilities
Could operate at massive scale across multiple training pipelines

<!-- ## Prerequisites

Check the roadmap for recommended prerequisites for this topic. -->

<!-- ## Resources

Resources and detailed content will be added soon. In the meantime, you can:

- Explore related topics in the curriculum
- Join the discussion in the community
- Contribute your own knowledge and resources

---

*Note: This is a placeholder page. Comprehensive content is under development.* -->

## Research Questions

## Recommended Reading