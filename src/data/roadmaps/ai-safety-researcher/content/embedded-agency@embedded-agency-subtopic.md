
              <h2>Embedded Agency</h2>
              <p>Traditional decision theory assumes agents are separate from their environment. Embedded agents are part of the world they're reasoning about.</p>
              
              <h3>Key Challenges</h3>
              <ul>
                <li><strong>Self-Reference:</strong> Agent's computations affect the world being modeled</li>
                <li><strong>Logical Uncertainty:</strong> Limited compute means uncertain about logical facts</li>
                <li><strong>Naturalized Induction:</strong> Learning while embedded in environment</li>
                <li><strong>Robust Delegation:</strong> Creating successors or modifying oneself</li>
              </ul>
              
              <h3>Decision Theory Problems</h3>
              <ul>
                <li>Newcomb's Problem and decision theory paradoxes</li>
                <li>Logical counterfactuals and updateless decision theory</li>
                <li>Coordination without communication</li>
                <li>Reflective stability and self-modification</li>
              </ul>
              
              <h3>Implications for AI Safety</h3>
              <ul>
                <li>AIs reasoning about their own training</li>
                <li>Self-fulfilling prophecies and fixed points</li>
                <li>Corrigibility and shutdown problems</li>
                <li>Value stability under self-improvement</li>
              </ul>
              
              <h3>Research Directions</h3>
              <ul>
                <li>Logical induction and bounded rationality</li>
                <li>Functional decision theory</li>
                <li>Cartesian frames and boundaries</li>
                <li>Finite factored sets</li>
              </ul>
            