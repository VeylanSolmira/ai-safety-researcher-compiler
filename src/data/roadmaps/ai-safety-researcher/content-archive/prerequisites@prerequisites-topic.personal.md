# Core Prerequisites (Personal View)

<!-- This is the personal/informal version of prerequisites@prerequisites -->

## Quick Overview

ðŸŽ¯ **What is this about?**

I'm attempting a radically different paradigm for aspiring AI Safety Researchers: **leading with an ethical and ecological orientation** rather than traditional STEM-centrism. 

While STEM knowledge is necessary for AI development, it's also ironically a primary source of AI risk. STEM's tendency toward hyperfocus, optimization of narrow metrics, and institutional capture by market forces creates dangerous blind spots. Market dynamics â€” with their coordination failures, externalities, and wealth concentration â€” become exponentially more dangerous when amplified by AI systems. We'll explore all technical aspects *to the deepest level that's necessary and safe to publicly explore* â€” but anchored in this broader systemic understanding.

This project helps motivated individuals develop ethical and effective safety impact on AI's generation, deployment, and integration into Earth's biosphere.

The project is designed to take motivated human beings and help them have ethical and useful safety impact on the generation, deployment, and integration of AI into Earth's biosphere.

ðŸ’­ **Why should you care?**

AI will reshape fundamental aspects of human existence: identity, labor, power structures, and potentially survival itself. We face substantial risks of societal stress, social collapse, mass loss of meaning, international conflict escalation, social cohesion breakdown, and existential threats.

ðŸ”‘ **Key Concepts**

This project organizes my thinking by creating the teaching materials both I and hypothetical students need to become effective AI safety researchers. We'll explore mathematical, machine learning, and computer science foundations as they directly connect to our safety objectives. Additionally, throughout the project, to the extent AI is used, went to *model responsible usage of AI in the context of AI safety research and learning*

## Learning Tips
Be prepared to be challenged and overwhelmed as we explore perhaps the most powerful technology ever created by our species.

---

*Note: Switch to Academic mode for the formal treatment of this topic.*

These prerequisites will ensure you can engage meaningfully with the interdisciplinary impact of AI technology, from understanding its technical content, challenges to human identity and moral status, reflection on expanding moral circles among many other topics neglected by capabilities-focused AI communities.

## Cognitive Orientation

### Ethics
- Appreciation for value pluralism and moral uncertainty
- Comfort with moral disagreement and ethical complexity
- Ability to think about long-term and systemic consequences
- Understanding of power dynamics and distributive justice

### Critical Thinking Skills
- Epistemic humility
- Systems thinking and incentive analysis
- Willingness to challenge widely held beliefs and claims

### Learning and Meta-Learning
- **Epistemic resilience**: Comfort with confusion as part of learning
- **Interdisciplinary synthesis**: Connecting insights across domains
- **Belief revision**: Changing views when evidence warrants
- **Active open-mindedness**: Engaging productively with disagreement

## Mathematical Foundations

### Probability and Statistics
- Probability distributions
- Bayes' theorem
- Expectation and variance
- Statistical inference
- Understanding of uncertainty

## Computer Science

### Python Proficiency
- Core Python programming

### Software Engineering Basics
- Version control (Git)
- Code organization and documentation

## Recommended Resources

### Communities
- LessWrong for rationality and AI safety discussions
- Alignment Forum for technical AI safety content
- Local EA/AI safety reading groups

## Self-Assessment

Before proceeding, you should be comfortable with:
- [ ] Willing to read a machine learning paper and iteratively working on understanding it deeply
- [ ] Interested in thinking critically about the societal impacts of AI
- [ ] Willing to develop and defend positions on AI governance that may conflict with major AI companies' interests