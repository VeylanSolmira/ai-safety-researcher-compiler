# AI Safety Researcher Curriculum Structure

This curriculum is available in two complementary views:
- **Roadmap View**: A comprehensive skill tree for self-directed exploration
- **Journey View**: A structured, tiered learning path with hands-on projects

---

## Roadmap View: Complete Skill Tree

### Prerequisites
- (To be defined - ML basics, Python, etc.)

### 1. Foundations

#### Core Computer Science
- Docker & Containerization
- Distributed Systems
- Version Control

#### Philosophy
- Ethics
- Political

#### AI Safety Paradigms
- Control
- Alignment
- Value Learning

#### AI Systems & Training
- Types of AI Systems
- LLMs
- How LLMs are Trained
- Pretraining
- Fine-tuning

#### Research Methodology & Execution
- Problem Decomposition & Scoping
- Iterative Research Design
- Research Project Management

### 2. Alignment Fundamentals

#### Core Concepts
- Core Methodology
- Teacher vs. Trainer
- Multi-Agent Environments
- Hallucinations
- Foundational Papers
- Key Figures

#### Sources of AI Risk
- Agency
- Impenetrability
- Situational awareness

#### AI Risk Areas
- Existential Risk
- Timeline Considerations
- Disrupting Research
- Neel Nanda
- Far

#### Interpretability & Transparency
- Interpretability
- Transparency

#### Assessment & Benchmarking
- Capability Assessments
- Risk Assessment Methodologies
- Assessment Frameworks
- Safety Benchmarks

### 3. Advanced AI Safety

#### AI Agents & Systems
- AI Agents
- Computer Security
- Agency
- Resource Tracking
- Docker

#### Red Teaming & Security
- Red Teaming
- Red Teaming Protocols
- Constellation

#### Testing Approaches
- White-box Testing
- Black-box Testing
- Grey-box Testing

#### Attack & Defense
- Jailbreaking
- Adversarial Meta-Learning
- Prompt Injection
- Data Poisoning

#### Model Understanding
- Explainability
- Training Run Monitoring

### 4. Governance

#### Regulation & Policy
- Regulatory Approaches
- International Coordination
- National AI Strategies
- Yoshua Bengio

#### Implementation & Control
- Deployment Gates
- API Access Controls
- Hardware Controls
- Resource Allocation
- Enforcement Mechanisms
- Safety Oversight Bodies

#### Risk Management
- Safety-Capability Balance

### 5. Community & Collaboration
- Collaboration

---

## Journey View: Tiered Learning Path

### Foundation Tier (3 months)
**Goal**: Get your hands dirty with AI safety fundamentals

#### Module 1: AI Safety: Why It Matters (1 week)
*Path: All learners*

Topics:
1. **Prerequisites & Foundations** (2 hours)
   - Core prerequisites and AI safety foundations
   - Interactive resources and journey tips
   - *Features: Journey extras, assessment*

2. **Why AI Safety Matters** (2 hours)
   - Visceral examples of AI failures and near-misses
   - Case studies: Tay chatbot, Flash Crash 2010
   - *Features: Experiments*

3. **The AI Risk Landscape** (3 hours)
   - Map of AI risks from bias to existential threats
   - Exploration of risk taxonomy
   - *Features: Roadmap content*

4. **Your AI Safety Journey** (1 hour)
   - Interactive tool to find your ideal learning path
   - Path-finder quiz

#### Module 2: Practical AI Safety Basics (2 weeks)
*Path: Technical Safety, Engineering, Research*

Topics:
1. **Build Your First Safety Tool** (1 hour)
   - Create a simple AI output validator
   - *Features: Assessment*

2. **Red Teaming Fundamentals** (4 hours)
   - Learn to think like an attacker
   - Experiments: First jailbreak, prompt injection lab
   - Case study: DAN phenomenon

3. **Basic Interpretability** (5 hours)
   - Peek inside AI models
   - Experiments: Attention visualization, feature attribution

4. **Prompt Injection Attacks** (20 minutes)
   - Understand and defend against prompt injection
   - *Features: Assessment*

5. **Jailbreak Techniques** (20 minutes)
   - Learn about AI jailbreaking methods and defenses

6. **Safety Evaluation Methods** (6 hours)
   - Build your first safety benchmark
   - Experiments: Build safety eval, benchmark comparison

#### Module 3: Essential ML for Safety (3 weeks)
*Path: Technical Safety, Engineering, Research*

Topics:
1. **How LLMs Actually Work** (4 hours)
   - Demystify language models without heavy math
   - Experiments: Train tiny GPT, tokenization explorer

2. **When Training Goes Wrong** (3 hours)
   - Common failure modes and how to spot them
   - Case studies: GPT-2 controversy, model collapse

3. **The Safety-Capability Balance** (2 hours)
   - Understanding the fundamental tension
   - Exploration: Capability-control tradeoffs

#### Module 4: AI Safety Policy & Ethics Primer (2 weeks)
*Path: Governance*

Topics:
1. **Ethics in AI Development** (3 hours)
   - Core ethical principles for safe AI
   - Exploration: Ethical frameworks

2. **Global AI Policy Landscape** (4 hours)
   - Overview of AI regulations worldwide
   - Case study: EU AI Act overview

3. **AI Governance Fundamentals** (3 hours)
   - Introduction to institutional approaches

#### Module 5: Understanding AI Risks (2 weeks)
*Path: All learners*

Topics:
1. **Data Poisoning** (20 minutes)
   - How malicious data corrupts AI systems
   - *Features: Assessment*

2. **AI & Computer Security** (30 minutes)
   - Intersection of AI and traditional security

3. **AI Risk Assessment** (2 hours)
   - Learn to identify and evaluate AI risks
   - Workshop: Risk assessment

### Intermediate Tier (6 months)
**Goal**: Build real safety tools and contribute to the field

#### Module 1: Advanced Red Teaming & Adversarial ML (4 weeks)
*Path: Technical Safety, Research*

Topics:
1. **Automated Red Teaming Systems** (8 hours)
   - Build systems that automatically discover vulnerabilities
   - Case study: GPT-4 safety evals

2. **Adversarial Robustness Techniques** (10 hours)
   - Defense mechanisms against adversarial attacks
   - *Features: Assessment from legacy*

3. **Multimodal Attack Vectors** (12 hours)
   - Attacking AI through text, image, and audio
   - Lab: Multimodal jailbreak

#### Module 2: Production Safety Engineering (6 weeks)
*Path: Engineering, Technical Safety*

Topics:
1. **Real-time Safety Monitoring** (10 hours)
   - Monitor AI systems in production
   - Build: Monitoring dashboard

2. **Advanced Content Filtering** (12 hours)
   - Build sophisticated moderation systems
   - Exploration: Filter evasion techniques

3. **Safety API Design** (8 hours)
   - Design and implement safety-first APIs
   - Workshop: Safety API design

4. **AI Incident Response** (6 hours)
   - Handle safety incidents in production
   - Case studies: Tay, Bing Sydney

#### Module 3: Applied Interpretability (5 weeks)
*Path: Technical Safety, Research, Engineering*

Topics:
1. **Mechanistic Interpretability Practice** (12 hours)
   - Reverse engineer neural network behaviors
   - Labs: Circuit discovery, neuron analysis

2. **Building Explainable AI Systems** (10 hours)
   - Create AI that can explain decisions
   - Case study: Medical AI explanations

3. **AI Debugging Frameworks** (8 hours)
   - Tools and techniques for debugging AI
   - Build: Debugger, behavior tracer

#### Module 4: AI Governance Fundamentals (4 weeks)
*Path: Governance*

Topics:
1. **AI Policy Analysis** (8 hours)
   - Analyze and evaluate AI safety policies
   - Case studies: EU AI Act, Executive Orders

2. **Safety Institutions Design** (10 hours)
   - Design institutions for AI safety oversight
   - Case study: UK AISI formation

3. **International AI Coordination** (6 hours)
   - Understand global coordination challenges
   - Exploration: Coordination game theory

### Advanced Tier (6 months)
**Goal**: Contribute original research and push the field forward

#### Module 1: Alignment Research Methods (8 weeks)
*Path: Research, Technical Safety*

Topics:
1. **Deep Dive: Alignment Principles** (45 minutes)
   - Comprehensive exploration of AI alignment theory
   - *Features: Assessment, AI Teacher*

2. **AI Safety Research Methodology** (12 hours)
   - Learn to conduct rigorous safety research
   - Exploration: Research best practices

3. **Advanced Alignment Theory** (16 hours)
   - Deep dive into theoretical challenges
   - Explorations: Mesa-optimization, inner alignment

4. **Empirical Alignment Research** (20 hours)
   - Run experiments on alignment techniques
   - Labs: RLHF implementation, Constitutional AI

#### Module 2: Cutting-Edge Interpretability (8 weeks)
*Path: Technical Safety, Research, Engineering*

Topics:
1. **Novel Circuit Discovery** (20 hours)
   - Find and analyze new computational structures
   - Lab: Advanced circuit hunting

2. **Scalable Interpretability Methods** (16 hours)
   - Develop interpretability for large models
   - Build: Automated interp tools

#### Module 3: Advanced Safety Systems Design (10 weeks)
*Path: Engineering*

Topics:
1. **Distributed Safety Systems** (24 hours)
   - Build safety systems that scale
   - Lab: Multi-agent safety

2. **Safety Infrastructure Design** (20 hours)
   - Design infrastructure for safe AI deployment
   - Case study: Anthropic infrastructure

3. **Hardware-Level Safety Controls** (16 hours)
   - Implement safety at the hardware level
   - Exploration: Hardware security models

#### Module 4: Advanced AI Governance & Policy (8 weeks)
*Path: Governance*

Topics:
1. **AI Policy Design & Analysis** (20 hours)
   - Create and evaluate effective AI safety policies
   - Case studies: Policy impact studies

2. **Global AI Governance** (24 hours)
   - Lead international coordination efforts
   - Exploration: Game theory coordination

3. **Enforcement & Compliance Systems** (16 hours)
   - Design systems for AI safety compliance
   - Experiment: Compliance monitoring

### Expert Tier (Ongoing)
**Goal**: Lead the field and train the next generation

#### Module 1: Research Leadership (Ongoing)
*Path: All*

Topics:
1. **Setting Research Agendas** (12 hours)
   - Define impactful research directions
   - Case studies: Anthropic, DeepMind teams

2. **Building Safety Teams** (10 hours)
   - Recruit and develop AI safety talent
   - Exploration: Talent development

#### Module 2: Field Building (Ongoing)
*Path: All*

Topics:
1. **Mentoring Next Generation** (8 hours)
   - Develop the next wave of researchers
   - Exploration: Effective mentorship

2. **Building Safety Institutions** (12 hours)
   - Create lasting organizations for AI safety
   - Case studies: MIRI founding, FHI history

---

## Learning Path Options

Choose your specialization:

- **Technical Safety**: Focus on interpretability, red teaming, and technical alignment solutions
- **Governance**: Emphasize policy, regulation, and institutional approaches
- **Engineering**: Build production-ready safety systems and infrastructure
- **Research**: Conduct original research and push theoretical boundaries
- **All Paths**: Get a comprehensive overview of all aspects

Each path filters the modules to show only relevant content while ensuring everyone gets essential foundational knowledge.