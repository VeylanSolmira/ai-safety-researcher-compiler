# AI Safety Researcher Curriculum Structure

## Prerequisites
- (To be defined - ML basics, Python, etc.)

## 1. Foundations

### Core Computer Science
- Docker & Containerization
- Distributed Systems
- Version Control

### Philosophy
- Ethics
- Political

### AI Safety Paradigms
- Control
- Alignment
- Value Learning

### AI Systems & Training
- Types of AI Systems
- LLMs
- How LLMs are Trained
- Pretraining
- Fine-tuning

### Research Methodology & Execution
- Problem Decomposition & Scoping
- Iterative Research Design
- Research Project Management

## 2. Alignment Fundamentals

### Core Concepts
- Core Methodology
- Teacher vs. Trainer
- Multi-Agent Environments
- Hallucinations
- Foundational Papers
- Key Figures

### Sources of AI Risk
- Agency
- Impenetrability
- Situational awareness

### AI Risk Areas
- Existential Risk

## 3. Specialization Paths

## 4. Technical Alignment

### Testing Contexts
- White Box Testing
- Black Box Testing
- Grey Box Testing

### Interpretability Techniques
- Explainability
- Interpretability
- Transparency

### Security & Attacks
- Prompt Injection
- Jailbreak Techniques
- Data Poisoning
- Computer Security
- Adversarial Meta-Learning
    - Safety Discourse Capture
    - Recursive Deception in Training
    - **Recursive Self-Improvement**
    - Strategic Publication Restraint

## 5. AI Governance

### Policy Frameworks
- National AI Strategies
- International Coordination
- Regulatory Approaches

### Institutional Design
- Safety Oversight Bodies
- Assessment Frameworks
- Enforcement Mechanisms

### Strategic Interventions
- Risk Assessment Methodologies
- Timeline Considerations
- Resource Allocation

## 6. Technical Governance

### Compute Governance
- Training Run Monitoring
- Hardware Controls
- Resource Tracking

### Model Evaluations
- Safety Benchmarks
- Capability Assessments
- Red Teaming Protocols

### Institutional Mechanisms
- API Access Controls
- Deployment Gates
- Safety-Capability Balance

## 7. Advanced Research

### Research Methods
- Red Teaming
- AI Agents
- Disrupting AI Safety Research
- Collaboration

### Organizations
- Constellation
- FAR (Fund for Alignment Research)

